# 인공지능과 머신러닝

1950년 대 태동기를 시작으로 투자나 관심이 줄어들었던 암흑기, 1990년 대 머신러닝이라는 대체 개념의 등장으로 AI 분야에 대한 연구가 다신 활발해졌던 도약기로 나뉠 수 있음.



### 머신러닝의 유형

 머신러닝은 지도학습, 비지도학습, 강화학습 세 가지로 분류됩니다.

| 지도학습                                            | 비지도학습                                                   |
| --------------------------------------------------- | ------------------------------------------------------------ |
| 주어진 입출력 데이터들의 관계로부터 매핑함수를 학습 | 데이터 간의 패턴을 통해, 데이터 내에 숨겨진 구조를 발견 및 학습 |
| 정답이 존재                                         | 정답이 없음                                                  |
| 이미지 분류, 이미지 캡셔닝, 객체 인식               | 데이터 클러스터링, 특성 학습, 밀도 추정                      |



### Neural Networks(NN)과 Multi-Layer Perceptron(MLP)

퍼셉트론은 가장 기본적인 신경망 구조를 의미합니다. 퍼셉트론을 다중으로 쌓은 것을 MLP라고 합니다.

NN의 최종 출력이 타겟의 차원과 일치하도록 설계를 하고, 입력과 원하는 출력(라벨)이 기술된 데이터들을 이용하여 파라미터를 학습합니다. NN에 입력 값을 넣었을 때 마지막 층에서 나온 출력과 라벨의 차이(오차)로 네트워크를 학습합니다. MLP에서 Error를 층층이 쌓인 레이어들로 전파하는 기술을 오차역전파 라고 합니다. 그리고 Error를 전달받은 레이어들은 경사하강법을 통하여 학습하게 됩니다. 이것이 뉴럴넷에서의 학습입니다.



### 용어 정리

* 인공지능: 인공지능(AI)은 인식, 학습, 추론, 문제 해결, 의사 결정 등 일반적으로 인간의 지능이 필요한 작업을 기계가 수행할 수 있는 능력을 말한다. 인공지능은 기계 학습, 딥 러닝, 자연어 처리, 컴퓨터 비전, 로봇 공학 등 다양한 하위 분야를 포괄하는 광범위한 분야이다.

* 머신러닝: 기계가 명시적으로 프로그래밍되지 않고 데이터에서 학습할 수 있도록 한다. 

* 딥러닝: 인공 신경망을 사용하여 인간의 뇌를 시뮬레이션하고 많은 양의 복잡한 데이터를 처리하는 기계 학습의 하위 집합이다.

* 지도학습: 데이터 포인트가 해당 레이블과 쌍을 이루는 레이블이 지정된 데이터 세트에서 기계 학습 모델을 훈련하는 것을 포함한다. 모델의 목표는 입력 기능과 출력 레이블 간의 매핑을 학습하여 보이지 않는 새로운 데이터 지점의 레이블을 정확하게 예측할 수 있도록 하는 것이다. 지도 학습 과제의 몇 가지 예로는 이미지 분류, 음성 인식 및 스팸 탐지가 있다.

* 비지도학습: 명시적인 레이블 없이 레이블이 없는 데이터 세트에서 패턴이나 구조를 식별하는 것이다. 이 모델은 데이터 포인트 간의 유사성과 차이점을 식별하고 유사성을 기반으로 클러스터로 그룹화하는 방법을 학습한다. 비지도 학습은 종종 이상 탐지, 고객 세분화 및 차원 축소와 같은 작업에 사용된다.

* Neural Networks (NN): 인공 신경망은 인간 뇌의 구조와 기능에서 영감을 받은 기계 학습 모델의 한 종류이다.

* Multi Layer Perceptron (MLP):  여러 개의 뉴런 층으로 구성된 인공 신경망의 한 유형으로, 각 층은 이전 층과 다음 층에 완전히 연결되어 있다. 그것은 회귀 및 분류 작업에 모두 사용되는 지도 학습 알고리듬이다.

* 자연어 처리: 컴퓨터와 인간 언어 사이의 상호 작용에 초점을 맞춘 인공지능의 하위 분야이다. 그것은 자연어를 처리하고 이해하고 생성할 수 있는 알고리즘과 계산 모델을 개발하는 것을 포함한다.

* 순환 신경망(RNN): 시퀀스 데이터 처리에 일반적으로 사용되는 신경망의 한 유형이다. 입력 데이터를 단일 패스로 처리하는 피드포워드 신경망과 달리, RNN은 가변 길이의 시퀀스를 처리할 수 있는 내부 상태 또는 "메모리"를 유지할 수 있다.

  RNN은 자연어 처리, 음성 인식 및 시계열 분석에서 순차 데이터를 처리하는 데 특히 유용하다. 시퀀스의 각 요소에 동일한 신경망 기능을 재귀적으로 적용하여 가변 길이의 입력을 처리하는 동시에 해당 시점까지 시퀀스에 대한 정보를 캡처하는 내부 메모리를 유지하도록 설계되었다.

* Sequence-to-sequence (seq2seq): 기본 아이디어는 인코더와 디코더라는 두 개의 반복 신경망(RNN)을 사용하는 것이다. 인코더는 입력 데이터의 시퀀스를 받아들여 입력 시퀀스에 포함된 주요 정보를 캡처하는 고정 길이 벡터 표현(콘텍스트 벡터라고도 함)을 생성한다. 그런 다음 디코더는 컨텍스트 벡터를 가져와서 출력 데이터의 새로운 시퀀스를 생성하기 위해 사용한다.

* 트랜스포머: 트랜스포머는 인코더와 디코더로 구성되며, 둘 다 자기 주의 및 피드포워드 신경망의 여러 레이어로 구성된다. 자기 주의는 모델이 입력 시퀀스의 다른 부분에 주의를 기울일 수 있게 하여 기존의 반복 신경망(RNN)보다 입력 시퀀스와 출력 시퀀스 사이의 장거리 종속성을 더 효과적으로 포착할 수 있게 한다. 피드포워드 네트워크는 자기 주의 계층의 출력을 다른 차원으로 변환하는 방법을 제공한다.

* Speech Synthesis(Text To Speech): TTS 시스템은 일반적으로 자연어 처리(NLP)와 디지털 신호 처리(DSP) 기술을 조합하여 텍스트에서 음성을 생성한다. 입력된 텍스트를 분석해 단어와 문장별로 적절한 발음과 억양을 파악하는 것이 기본 아이디어다.

* 스펙트로그램(spectrogram): 신호의 주파수 스펙트럼이 시간에 따라 변하는 것을 시각적으로 표현한 것이다. 신호 처리에서 흔히 사용되는 도구이며 음성 인식, 음악 분석, 사운드 엔지니어링과 같은 오디오 처리 및 분석에 자주 사용된다.

* 보코더(vocoder): 음성이나 다른 소리를 분석하고 합성하는 데 사용되는 신호 처리 시스템의 일종이다. 그것은 사람의 목소리와 같은 입력 신호의 스펙트럼 내용을 분석하고 그 정보를 사용하여 다른 스펙트럼 내용을 가진 새로운 신호를 합성함으로써 작동한다.

* bottleck: 신경망에서 이전과 이후의 계층보다 훨씬 적은 수의 노드 또는 뉴런을 가진 계층 또는 계층 집합을 말한다. 병목 계층은 종종 신경망의 중간에 배치되며 입력 데이터의 압축된 표현을 학습하도록 설계된다. 병목 현상 기능이라고도 하는 이 압축 표현은 데이터에 대한 가장 중요한 정보를 유지하면서 관련성이 낮은 정보는 폐기하는 입력 데이터의 저차원 표현이다.

* HiFi-GAN: 고품질 오디오 파형을 생성하도록 설계된 생성 모델입니다. 딥 러닝 기술을 사용하여 오디오 파형의 대규모 데이터 세트에 존재하는 통계 패턴과 기능을 학습한 다음, 해당 지식을 사용하여 원래 데이터 세트와 유사한 새로운 충실도 높은 오디오 샘플을 생성하는 신경망의 일종이다.

* Sub2

* 이미지 캠셔닝: 이미지 캡션은 이미지에 대한 텍스트 설명을 자동으로 생성할 수 있는 기술입니다. 이미지 캡션의 목표는 기계가 이미지의 시각적 내용을 이해하고 설명할 수 있도록 하고 이미지의 가장 중요한 측면을 캡처하는 자연어 캡션을 생성하는 것이다.

* CLIP(Contrastive Language-Image Pre-Training): 이미지와 자연어 텍스트를 동시에 처리할 수 있는 최첨단 딥 러닝 모델이다. OpenAI가 개발한 CLIP는 대조 학습 접근법을 사용하여 두 양식 모두에 대한 공동 표현 공간을 학습하는 것을 목표로 많은 양의 이미지-텍스트 쌍에서 신경망을 사전 훈련한다.

